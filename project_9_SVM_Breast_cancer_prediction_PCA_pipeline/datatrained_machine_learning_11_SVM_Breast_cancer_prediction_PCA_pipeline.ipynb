{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d055f8d6-76db-449e-9e39-7a66c241196f",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC for Classification\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# SVR for Regression\n",
    "\n",
    "0\n",
    "\n",
    "As usual always refer skiean official documentation if you are not sure about syntax or parameter\n",
    "\n",
    "bups://scikit-leam.org\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Support Vector Machine is a supervised Machine Learning algorithm widely used for soiving different machine learning problems. Given a dataset, the algorithm tries to divide the data using hyperpianos and then makes the predictions, SVM is a non-probabilistic linear classifier While other classifiers, when classifying, predict the probability of a data point to belong to one group or the another, SVM directly says to which group the datapoint belongs to without using any probability calculation.\n",
    "\n",
    "# Understanding the Mathematics involved\n",
    "\n",
    "Let's take the example of the following dataset and see now can we divide the data into appropriate groups.\n",
    "\n",
    "Python Silpykemeu\n",
    "\n",
    "A\n",
    "\n",
    "We can see that there are two groups of data. The question is how to divide these points into two groups. It can be done using any of the three lines. Or, for that purpose, there can be an infinite number of straight lines that can divide these points into two classes. Now, which line to choose? SVM solves this problem using the maximum margin as shown\n",
    "\n",
    "The black line in the middle is the optimum classifier. This line is drawn to maximise the distance of the classifier line from the nearest points in the two classes. It is also called a hyperplane in terms of SVM. A Hyperplane is an n-1 dimensional plane which optimally divides the data of n dimensions. Hore, as we have only a 2-D data, so the hyperplane can be represented using one dimension only. Hence, the hyporplane is a line here. The two points (highlighted with circles) which are on the yellow lines, they are called the support vectors. As it is a 2-D figure, they are points, in a multi-dimensional space, they will be vectors, and hence, the name- support vector machine as the aigorithm creates the optimum classification line by maximising its distance from the two support vectors.\n",
    "\n",
    "When the data is not linearly separable, then to create a hyperplane to separate data into different groups, the SVM algorithm needs to perform computations in a higher-dimensional space. But the introduction of new dimensions makes the computations for the SVMs more intensive, which impacts the algorithm performance. To rectify this, mathematicians came up with the approach of Kernel methods. Kernei methods use kernel functions available in mathematics. The unique feature of a kernel function is to compute in a higher-dimensional space without caiculating the new coordinates in that higher dimension, It Implicitly uses prodefined mathematical functions to do operations on the existing points which mimic the computation in a higher-dimensional space without adding to the computation cost as they are not actually calculating the coordinates in the higher dimension thereby avoiding the computation of calculating distances from the newly computed points. This is called the kernel trick.\n",
    "\n",
    "# Image: bogotobogo.com\n",
    "\n",
    "In the left diagram above, we nave a non-linear distribution of data as we can not classify a data using a linear equation. To solve this problem, we can project the points in a 3-dimensional space and then derive a plane which divides the data into two parts. In theory, that's what a kemei function does without computing the additional coordinates for the higher dimension.\n",
    "\n",
    "# Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f06d46d-d8ef-4944-a4c1-0f5eb64e23a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a305704d-afd8-43de-af95-8e6c30ee714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M        17.99         10.38          122.80     1001.0   \n",
       "842517           M        20.57         17.77          132.90     1326.0   \n",
       "84300903         M        19.69         21.25          130.00     1203.0   \n",
       "84348301         M        11.42         20.38           77.58      386.1   \n",
       "84358402         M        20.29         14.34          135.10     1297.0   \n",
       "...            ...          ...           ...             ...        ...   \n",
       "926424           M        21.56         22.39          142.00     1479.0   \n",
       "926682           M        20.13         28.25          131.20     1261.0   \n",
       "926954           M        16.60         28.08          108.30      858.1   \n",
       "927241           M        20.60         29.33          140.10     1265.0   \n",
       "92751            B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760         0.30010   \n",
       "842517            0.08474           0.07864         0.08690   \n",
       "84300903          0.10960           0.15990         0.19740   \n",
       "84348301          0.14250           0.28390         0.24140   \n",
       "84358402          0.10030           0.13280         0.19800   \n",
       "...                   ...               ...             ...   \n",
       "926424            0.11100           0.11590         0.24390   \n",
       "926682            0.09780           0.10340         0.14400   \n",
       "926954            0.08455           0.10230         0.09251   \n",
       "927241            0.11780           0.27700         0.35140   \n",
       "92751             0.05263           0.04362         0.00000   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  texture_worst  \\\n",
       "id                                            ...                  \n",
       "842302                0.14710         0.2419  ...          17.33   \n",
       "842517                0.07017         0.1812  ...          23.41   \n",
       "84300903              0.12790         0.2069  ...          25.53   \n",
       "84348301              0.10520         0.2597  ...          26.50   \n",
       "84358402              0.10430         0.1809  ...          16.67   \n",
       "...                       ...            ...  ...            ...   \n",
       "926424                0.13890         0.1726  ...          26.40   \n",
       "926682                0.09791         0.1752  ...          38.25   \n",
       "926954                0.05302         0.1590  ...          34.12   \n",
       "927241                0.15200         0.2397  ...          39.42   \n",
       "92751                 0.00000         0.1587  ...          30.37   \n",
       "\n",
       "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                           \n",
       "842302             184.60      2019.0           0.16220            0.66560   \n",
       "842517             158.80      1956.0           0.12380            0.18660   \n",
       "84300903           152.50      1709.0           0.14440            0.42450   \n",
       "84348301            98.87       567.7           0.20980            0.86630   \n",
       "84358402           152.20      1575.0           0.13740            0.20500   \n",
       "...                   ...         ...               ...                ...   \n",
       "926424             166.10      2027.0           0.14100            0.21130   \n",
       "926682             155.00      1731.0           0.11660            0.19220   \n",
       "926954             126.70      1124.0           0.11390            0.30940   \n",
       "927241             184.60      1821.0           0.16500            0.86810   \n",
       "92751               59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                                \n",
       "842302             0.7119                0.2654          0.4601   \n",
       "842517             0.2416                0.1860          0.2750   \n",
       "84300903           0.4504                0.2430          0.3613   \n",
       "84348301           0.6869                0.2575          0.6638   \n",
       "84358402           0.4000                0.1625          0.2364   \n",
       "...                   ...                   ...             ...   \n",
       "926424             0.4107                0.2216          0.2060   \n",
       "926682             0.3215                0.1628          0.2572   \n",
       "926954             0.3403                0.1418          0.2218   \n",
       "927241             0.9387                0.2650          0.4087   \n",
       "92751              0.0000                0.0000          0.2871   \n",
       "\n",
       "          fractal_dimension_worst  Unnamed: 32  \n",
       "id                                              \n",
       "842302                    0.11890          NaN  \n",
       "842517                    0.08902          NaN  \n",
       "84300903                  0.08758          NaN  \n",
       "84348301                  0.17300          NaN  \n",
       "84358402                  0.07678          NaN  \n",
       "...                           ...          ...  \n",
       "926424                    0.07115          NaN  \n",
       "926682                    0.06637          NaN  \n",
       "926954                    0.07820          NaN  \n",
       "927241                    0.12400          NaN  \n",
       "92751                     0.07039          NaN  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the csv data here and print head\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/training-ml/Files/main/breast%20cancer.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a46fd2-dfb0-4ebf-904a-e76ae758df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape-------> (569, 32)\n",
      "each column and data type and its count \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 569 entries, 842302 to 92751\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    object \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      " 31  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), object(1)\n",
      "memory usage: 146.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print summary\n",
    "print('shape------->',df.shape)\n",
    "print('each column and data type and its count','\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a667885-8e18-4aa3-9abb-9845872e0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Alert 1 : Unnamed:32 column has all nulls .safe to remove the column\n",
    "df=df.drop(['Unnamed: 32'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93acb946-648d-48c7-a617-7ebf58c6d9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856983a9-b9d0-4fa7-9d81-cb2e1d7acd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d56938-9500-423f-97de-445c61dfb2a6",
   "metadata": {},
   "source": [
    "seems no other cols have null.its safe to proceed\n",
    "\n",
    "as we can see each feature data scaled differently lets go ahead and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61aeb88d-c7f5-4a62-aa07-5a73ea87a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X=df.drop('diagnosis',axis=1)\n",
    "X_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c3adf-22e1-4b79-aa55-bcab92b1bddb",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "• PCA is dimension reduction technique (Not feature selection technique)\n",
    "\n",
    "PCA can be applied only on Features (not on target)\n",
    "\n",
    "• PCA can be applied when you have too many features and their correiation is not that significant with target.\n",
    "\n",
    "• PCA will also takes care of multicollinearity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b133563-4050-4b95-b079-68872900d1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19283683e+00,  1.94858307e+00, -1.12316616e+00, ...,\n",
       "        -3.39144536e-02,  4.56477199e-02, -4.71692081e-02],\n",
       "       [ 2.38780180e+00, -3.76817174e+00, -5.29292687e-01, ...,\n",
       "         3.26241827e-02, -5.68742432e-03, -1.86787626e-03],\n",
       "       [ 5.73389628e+00, -1.07517380e+00, -5.51747593e-01, ...,\n",
       "         4.70258247e-02,  3.14589659e-03,  7.50534755e-04],\n",
       "       ...,\n",
       "       [ 1.25617928e+00, -1.90229671e+00,  5.62730526e-01, ...,\n",
       "        -2.57775589e-03,  6.70621179e-03,  3.77041667e-03],\n",
       "       [ 1.03747941e+01,  1.67201011e+00, -1.87702933e+00, ...,\n",
       "        -6.80863833e-02, -8.41632764e-02, -2.37828222e-02],\n",
       "       [-5.47524330e+00, -6.70636791e-01,  1.49044308e+00, ...,\n",
       "        -9.51587894e-03, -6.09131090e-02, -1.94755854e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA()\n",
    "pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aed1b8cf-f974-4b0e-9d9e-043259237189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets plot scree plot to check the best components\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.grid(axis='both')\n",
    "plt.xticks(range(1,31,2))\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Varoance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1b37c-bc05-4408-96ce-55d47180efa8",
   "metadata": {},
   "source": [
    "around 13 principal components are able to explain >95% variance its safe to consider starting 13 PC's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39da6838-650a-43f6-806c-d8249654b6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192837</td>\n",
       "      <td>1.948583</td>\n",
       "      <td>-1.123166</td>\n",
       "      <td>3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>1.411424</td>\n",
       "      <td>2.159370</td>\n",
       "      <td>-0.398407</td>\n",
       "      <td>-0.157120</td>\n",
       "      <td>-0.877399</td>\n",
       "      <td>0.262956</td>\n",
       "      <td>-0.859018</td>\n",
       "      <td>0.103385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387802</td>\n",
       "      <td>-3.768172</td>\n",
       "      <td>-0.529293</td>\n",
       "      <td>1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.240987</td>\n",
       "      <td>-0.711902</td>\n",
       "      <td>1.106991</td>\n",
       "      <td>0.813118</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>-0.943524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733896</td>\n",
       "      <td>-1.075174</td>\n",
       "      <td>-0.551748</td>\n",
       "      <td>0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>0.541452</td>\n",
       "      <td>-0.668166</td>\n",
       "      <td>0.097374</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.454275</td>\n",
       "      <td>-0.605604</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>-0.410626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.122953</td>\n",
       "      <td>10.275589</td>\n",
       "      <td>-3.232790</td>\n",
       "      <td>0.152547</td>\n",
       "      <td>-2.960878</td>\n",
       "      <td>3.053422</td>\n",
       "      <td>1.429911</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>-1.405439</td>\n",
       "      <td>-1.116976</td>\n",
       "      <td>-1.151514</td>\n",
       "      <td>1.011318</td>\n",
       "      <td>-0.933270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.935302</td>\n",
       "      <td>-1.948072</td>\n",
       "      <td>1.389767</td>\n",
       "      <td>2.940639</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>-1.226495</td>\n",
       "      <td>-0.936213</td>\n",
       "      <td>0.636377</td>\n",
       "      <td>-0.263807</td>\n",
       "      <td>0.377707</td>\n",
       "      <td>0.651361</td>\n",
       "      <td>-0.110517</td>\n",
       "      <td>0.387945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.439315</td>\n",
       "      <td>-3.576817</td>\n",
       "      <td>2.459487</td>\n",
       "      <td>1.177314</td>\n",
       "      <td>-0.074824</td>\n",
       "      <td>-2.375193</td>\n",
       "      <td>-0.596130</td>\n",
       "      <td>-0.035471</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>-0.062651</td>\n",
       "      <td>0.123343</td>\n",
       "      <td>-0.051725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3.793382</td>\n",
       "      <td>-3.584048</td>\n",
       "      <td>2.088476</td>\n",
       "      <td>-2.506028</td>\n",
       "      <td>-0.510723</td>\n",
       "      <td>-0.246710</td>\n",
       "      <td>-0.716326</td>\n",
       "      <td>-1.113360</td>\n",
       "      <td>-0.105206</td>\n",
       "      <td>-0.108634</td>\n",
       "      <td>0.244803</td>\n",
       "      <td>0.222754</td>\n",
       "      <td>-0.192635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.256179</td>\n",
       "      <td>-1.902297</td>\n",
       "      <td>0.562731</td>\n",
       "      <td>-2.089227</td>\n",
       "      <td>1.809991</td>\n",
       "      <td>-0.534447</td>\n",
       "      <td>-0.192758</td>\n",
       "      <td>0.341886</td>\n",
       "      <td>0.393920</td>\n",
       "      <td>0.520872</td>\n",
       "      <td>-0.840514</td>\n",
       "      <td>0.096477</td>\n",
       "      <td>0.157425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>10.374794</td>\n",
       "      <td>1.672010</td>\n",
       "      <td>-1.877029</td>\n",
       "      <td>-2.356031</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.223082</td>\n",
       "      <td>-0.280238</td>\n",
       "      <td>-0.542036</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.178627</td>\n",
       "      <td>-0.697462</td>\n",
       "      <td>1.225192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-5.475243</td>\n",
       "      <td>-0.670637</td>\n",
       "      <td>1.490443</td>\n",
       "      <td>-2.299157</td>\n",
       "      <td>-0.184703</td>\n",
       "      <td>1.617837</td>\n",
       "      <td>1.698951</td>\n",
       "      <td>1.046354</td>\n",
       "      <td>0.374099</td>\n",
       "      <td>-0.047722</td>\n",
       "      <td>-0.144093</td>\n",
       "      <td>-0.179499</td>\n",
       "      <td>0.678894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1        PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0     9.192837   1.948583 -1.123166  3.633731 -1.195110  1.411424  2.159370   \n",
       "1     2.387802  -3.768172 -0.529293  1.118264  0.621775  0.028656  0.013358   \n",
       "2     5.733896  -1.075174 -0.551748  0.912083 -0.177086  0.541452 -0.668166   \n",
       "3     7.122953  10.275589 -3.232790  0.152547 -2.960878  3.053422  1.429911   \n",
       "4     3.935302  -1.948072  1.389767  2.940639  0.546747 -1.226495 -0.936213   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "564   6.439315  -3.576817  2.459487  1.177314 -0.074824 -2.375193 -0.596130   \n",
       "565   3.793382  -3.584048  2.088476 -2.506028 -0.510723 -0.246710 -0.716326   \n",
       "566   1.256179  -1.902297  0.562731 -2.089227  1.809991 -0.534447 -0.192758   \n",
       "567  10.374794   1.672010 -1.877029 -2.356031 -0.033742  0.567936  0.223082   \n",
       "568  -5.475243  -0.670637  1.490443 -2.299157 -0.184703  1.617837  1.698951   \n",
       "\n",
       "          PC8       PC9      PC10      PC11      PC12      PC13  \n",
       "0   -0.398407 -0.157120 -0.877399  0.262956 -0.859018  0.103385  \n",
       "1    0.240987 -0.711902  1.106991  0.813118  0.157925 -0.943524  \n",
       "2    0.097374  0.024066  0.454275 -0.605604  0.124389 -0.410626  \n",
       "3    1.059565 -1.405439 -1.116976 -1.151514  1.011318 -0.933270  \n",
       "4    0.636377 -0.263807  0.377707  0.651361 -0.110517  0.387945  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "564 -0.035471  0.987929  0.256990 -0.062651  0.123343 -0.051725  \n",
       "565 -1.113360 -0.105206 -0.108634  0.244803  0.222754 -0.192635  \n",
       "566  0.341886  0.393920  0.520872 -0.840514  0.096477  0.157425  \n",
       "567 -0.280238 -0.542036 -0.089294 -0.178627 -0.697462  1.225192  \n",
       "568  1.046354  0.374099 -0.047722 -0.144093 -0.179499  0.678894  \n",
       "\n",
       "[569 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=13)\n",
    "new_pcomp=pca.fit_transform(X_scaled)\n",
    "princi_comp=pd.DataFrame(new_pcomp,columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13'])\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54109005-1874-4f24-9dc7-1efdeb9d1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace label column (diagnosis) into binary codes\n",
    "df['diagnosis']=df['diagnosis'].replace({'M':1,'B':0})\n",
    "y=df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a357fe3-ea44-4bd1-8272-b0044abf8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split into train and test\n",
    "x_train,x_test,y_train,y_test=train_test_split(princi_comp,y,test_size=0.25,random_state=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56fbef8-ed25-447f-a197-f9b8babc27f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf,x_train,x_test,y_train,y_test,train=True):\n",
    "    if train:\n",
    "        y_pred=clf.predict(x_train)\n",
    "        print(\"\\n====================train result================\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_train,y_pred)*100:.2f}%\")\n",
    "\n",
    "    elif train==False:\n",
    "        pred=clf.predict(x_test)\n",
    "        print(\"\\n=============test result==========\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        print(\"\\n test classification report\\n\",classification_report(y_test,pred,digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d47e7-db88-46ef-b323-b71b9a9331b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================train result================\n",
      "Accuracy Score:98.12%\n",
      "\n",
      "=============test result==========\n",
      "Accuracy Score:97.90%\n",
      "\n",
      " test classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.94      0.97        50\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "#  svc model training and printing train and test score\n",
    "svc.fit(x_train,y_train)\n",
    "# call the function and pass dataset to check train and test score\n",
    "\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=True)\n",
    "\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507c18b-4436-4b4c-8069-273baef394a1",
   "metadata": {},
   "source": [
    "# Similarly you can use preprocessed data and build other models and check the score\n",
    "\n",
    "# Hyperparameter tuning\n",
    "\n",
    "\n",
    "\n",
    "= It is a hypermeter in SVM to control error, How much error we can allow.\n",
    "\n",
    "# C\n",
    "\n",
    "Low C means allowing Less number of error's and\n",
    "\n",
    "#\n",
    "\n",
    "Large C means allowing more number of errors.\n",
    "\n",
    "gamma Gamma decides that how much curvature we want inr. a decision boundary. Gamma ingh means more curvature. #\n",
    "\n",
    "Garima Low means Less curvature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeba4dab-f53f-4cf6-a73f-cd3c30c300ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'C':[1,5,10,20],\n",
    "           'gamma':[0.001,0.01,0.02,0.002]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b944d7af-9ab0-4b4b-bb15-14e395daf99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'gamma': 0.01}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch=GridSearchCV(svc,param_grid)\n",
    "gridsearch.fit(x_train,y_train)\n",
    "\n",
    "# best parms\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decd3081-dc1c-4ea6-9114-4fa333d0bf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=5, gamma=0.01)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC model training and printing train and test score (past param update)\n",
    "svc=SVC(C=5,gamma=0.01)\n",
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ad4d949-521c-4896-97d9-3bfc719e6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================train result================\n",
      "Accuracy Score:98.12%\n",
      "\n",
      "=============test result==========\n",
      "Accuracy Score:97.90%\n",
      "\n",
      " test classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        93\n",
      "           1       1.00      0.94      0.97        50\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.97      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and pass dataset to check train and test score\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=True)\n",
    "print_score(svc,x_train,x_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d1de4-6e4e-42d0-8dd9-da4099ae8cb2",
   "metadata": {},
   "source": [
    "\n",
    "# Creating Pipeline\n",
    "\n",
    "In real world the final model is built wipipeline. We work on all preprocessing steps, do EDA, make analysis etc. Once we find all the hyperparameter and feature selection techniques etc, We use the main techniques and create pipeline. This will be clean and better flow of data through series of sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6002d188-9d10-4e63-99ed-c33c7bf3929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42acc78-006b-421f-ad28-2658f3b783eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('https://raw.githubusercontent.com/training-ml/Files/main/breast%20cancer.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34e297d9-abc5-4a9d-a9eb-14f951861cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['Unnamed: 32','diagnosis'],axis=1)\n",
    "y=df.diagnosis\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "243641e4-ca2a-461a-9c6f-c5bbcdbe5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('Scaler',StandardScaler()),# fit transform\n",
    "              ('PCA',PCA(n_components=13)), # fit_transform\n",
    "              ('SVM',SVC(C=7,gamma=0.01))]) # Only fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3425d2c5-120e-4bca-ab00-b44083bdd30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=13)),\n",
       "                (&#x27;SVM&#x27;, SVC(C=7, gamma=0.01))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=13)),\n",
       "                (&#x27;SVM&#x27;, SVC(C=7, gamma=0.01))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=13)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=7, gamma=0.01)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Scaler', StandardScaler()), ('PCA', PCA(n_components=13)),\n",
       "                ('SVM', SVC(C=7, gamma=0.01))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "521e1d6a-131a-4a44-84ed-adce7dfb626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c2c0a60-e578-4a25-a8e9-49b1e25ee014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.9020979020979"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435006df-d098-49a7-94c4-1343f44285d1",
   "metadata": {},
   "source": [
    "# Key Points\n",
    "\n",
    "You need to know the execution sequence, (example - Imputation techniques should be applied before standard scaler and then PCA\n",
    "\n",
    "You cannot use pipeline for plotting graphs and analysis.\n",
    "\n",
    "Analysis can be done before creating a pipeline.\n",
    "\n",
    "Do not use unnecessary methods in the Pipeline.\n",
    "\n",
    "You can also use any encoding/imputation techniques in the pipeline like.\n",
    "\n",
    "('Simple Imputer, Simplelmputerįstrategy=mean')), #fit_transform\n",
    "\n",
    "('Ohe', OneHotEncoder(handle_unknown='ignore')), # fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c010c9f-2455-4210-8e2c-6a8a9a69e928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
